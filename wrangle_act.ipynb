{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Wrangling, analyzing and visualizing all h\\*ckin' good boys and girls !!  \n",
    "\n",
    "Twitter user [dog_rates](https://twitter.com/dog_rates) AKA [WeRateDogs](https://en.wikipedia.org/wiki/WeRateDogs)\n",
    "\n",
    "###### For more on Doggolingo check link below \n",
    "[Dogs Are Doggos: An Internet Language Built Around Love For The Puppers](https://www.npr.org/sections/alltechconsidered/2017/04/23/524514526/dogs-are-doggos-an-internet-language-built-around-love-for-the-puppers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"jmp2lnks\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1q27qppQ80W_giOg6vN0ngcvl_30Qgpcp\" width=\"100\">\n",
    "\n",
    "* <a href=\"#gathereddataframes\" style='color:#8D38C9'>Gathered DataFrames</a>\n",
    "* <a href=\"#assessmentoutcome\" style='color:#8D38C9'>Assessment outcome</a>\n",
    "* <a href=\"#cln\" style='color:#8D38C9'>Data cleaning process</a>\n",
    "* <a href=\"#masterdataframes\" style='color:#8D38C9'>Master DataFrame(s)</a>\n",
    "* <a href=\"#analysis\" style='color:#8D38C9'>Analysis and visualization</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather\n",
    "\n",
    "We will be gathering data from different sources and in different formats, the aim is to have a master DataFrame(s) including several details about tweets and dogs to help us in latter analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from functools import reduce\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import squarify\n",
    "import random\n",
    "import warnings;warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"twtarch\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe\n",
    "twt_arch_df=pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"imgprd\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and save image-predictions file\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "\n",
    "response = requests.get(url)\n",
    "with open(\"image-predictions.tsv\", mode='wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe\n",
    "img_predicts_df=pd.read_csv('image-predictions.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"twtapi\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to reproduce, use your own keys for accessing the API\n",
    "\n",
    "# # Query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n",
    "# consumer_key = ''\n",
    "# consumer_secret = ''\n",
    "# access_token = ''\n",
    "# access_secret = ''\n",
    "\n",
    "# auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "# auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "# api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# tweet_ids = twt_arch_df.tweet_id.values\n",
    "\n",
    "# # Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "# count = 0\n",
    "# fails_dict = {}\n",
    "# start = timer()\n",
    "# # Save each tweet's returned JSON as a new line in a .txt file\n",
    "# with open('tweet_json.txt', 'w') as outfile:\n",
    "#     for tweet_id in tweet_ids:\n",
    "#         count += 1\n",
    "#         print(str(count) + \": \" + str(tweet_id))\n",
    "#         try:\n",
    "#             tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "#             print(\"Success\")\n",
    "#             json.dump(tweet._json, outfile)\n",
    "#             outfile.write('\\n')\n",
    "#         except tweepy.TweepError as e:\n",
    "#             print(e)\n",
    "#             fails_dict[tweet_id] = e\n",
    "#             pass\n",
    "# end = timer()\n",
    "# print(end - start)\n",
    "\n",
    "# save missing tweets, incase needed latter\n",
    "# fails_df=pd.DataFrame(fails_dict.items())\n",
    "# fails_df.to_csv('Missing Tweets', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Tweet Json file and extract data\n",
    "\n",
    "# list to append data for latter conversion into a datframe\n",
    "df_list = []\n",
    "\n",
    "with open ('tweet_json.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        tweet_data=json.loads(line)\n",
    "        t_id=tweet_data['id']\n",
    "        rt_count=tweet_data[\"retweet_count\"]\n",
    "        fvt_count=tweet_data[\"favorite_count\"]\n",
    "        t_txt=tweet_data['full_text']\n",
    "        df_list.append({\n",
    "            'tweet_id':t_id,\n",
    "            'retweet_count':rt_count,\n",
    "            'favorite_count':fvt_count,\n",
    "            'full_text':t_txt,\n",
    "        })\n",
    "\n",
    "# convert list into dataframe\n",
    "twt_api_df = pd.DataFrame(df_list, columns=('tweet_id', 'retweet_count', 'favorite_count','full_text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"dgbrd\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://dogtime.com/dog-breeds/profiles'\n",
    "# connect to url\n",
    "response = requests.get(url)\n",
    "\n",
    "# Work with HTML file directly without downloading:\n",
    "soup = bs(response.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain all dog breeds details (name,image,info,links)\n",
    "\n",
    "# list to append data for latter conversion into a datframe\n",
    "dog_breed_list = []\n",
    "\n",
    "# list of urls from which breed details will be extracted, this is obtained from reading main url HTML file and locating position of needed data\n",
    "breed_url_list= ['article-crumbs group-letter letter-a js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-b js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-c js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-d js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-e js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-f js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-g js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-h js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-i js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-j js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-k js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-l js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-m js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-n js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-o js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-p js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-r js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-s js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-t js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-v js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-w js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-x js-letter-section paws',\n",
    "                 'article-crumbs group-letter letter-y js-letter-section paws',\n",
    "                ]\n",
    "\n",
    "\n",
    "# iterate through the list and extract required data\n",
    "for clss in breed_url_list:\n",
    "    dog_breed= soup.find('div', class_=clss).find_all(class_=\"list-item-title\")\n",
    "    dog_breed_info = soup.find('div', class_=clss).find_all(class_=\"list-item-img\")\n",
    "    dog_breed_img = soup.find('div', class_=clss).find_all(class_=\"list-item-breed-img\")\n",
    "    for text in dog_breed:\n",
    "        dog_breed_list.append({'breed':text.text})\n",
    "    for inf in dog_breed_info:\n",
    "        dog_breed_list.append({'breed_info_link':inf.attrs['href']})\n",
    "    for img in dog_breed_img:\n",
    "        dog_breed_list.append({'breed_img_link':img.attrs['src']})  \n",
    "\n",
    "# creat df and save data to csv file\n",
    "breed_df = pd.DataFrame(dog_breed_list, columns=['breed', 'breed_info_link', 'breed_img_link'])\n",
    "breed_df = breed_df.apply(lambda x: pd.Series(x.dropna().values))\n",
    "breed_df.to_csv('dog_breed_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"dgbrdinfo\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This cell took sometime to run, 385 url to pharse. Uncomment to reproduce.\n",
    "# # U can skip this step, it is just to extracts info text for display in the dataframe instead of going to the web site and reading from there\n",
    "# # breed info links already extracted\n",
    "\n",
    "# # info text links from which data will be extracted \n",
    "\n",
    "# url_array=breed_df.breed_info_link.values\n",
    "\n",
    "# breed_info_text_list=[]\n",
    "# count = 0\n",
    "\n",
    "# # iterate \n",
    "# for i in url_array:\n",
    "#     count +=1\n",
    "#     print(str(count) + \": \" + str(i))\n",
    "#     response=requests.get(i)\n",
    "#     soup=bs(response.content, 'lxml')\n",
    "#     breed_info_text = soup.find('div', class_='breeds-single-intro').find('p').text\n",
    "#     breed_info_text_list.append({i.split('/')[-1]:breed_info_text})\n",
    "#     print(\"Success\")\n",
    "\n",
    "# # save\n",
    "# breed_info_df = pd.DataFrame([(key, value) for i in breed_info_text_list for key, value in i.items()], columns=['breed','breed_info_text'])\n",
    "# breed_info_df.to_csv('dog_breed_info_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"gathereddataframes\"></a>\n",
    "### Gathered DataFrames\n",
    "\n",
    "* <a href=\"#twtarch\" style='color:#8D38C9'>Twitter Archive</a>\n",
    "* <a href=\"#imgprd\" style='color:#8D38C9'>Image Predictions</a>\n",
    "* <a href=\"#twtapi\" style='color:#8D38C9'>Twitter API</a>\n",
    "* <a href=\"#dgbrd\" style='color:#8D38C9'>Dog Breed</a>\n",
    "* <a href=\"#dgbrdinfo\" style='color:#8D38C9'>Dog Breed Info</a>\n",
    "\n",
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting  display options, increase width and row numbers to remove truncation\n",
    "pd.options.display.max_colwidth=150\n",
    "pd.options.display.max_rows=100\n",
    "pd.options.display.large_repr='truncate'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#assessmentoutcome\" style='color:#8D38C9'>Assessment outcome</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"arcdf\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_arch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_arch_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_arch_df.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_arch_df.tweet_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assessing incorrect rating scale for denominator, official is 10\n",
    "fltrd_rtng_dnm=twt_arch_df[(twt_arch_df.rating_denominator!=10) & twt_arch_df.in_reply_to_status_id.isnull() & twt_arch_df.retweeted_status_id.isnull()].drop(['in_reply_to_status_id','in_reply_to_user_id','retweeted_status_id','retweeted_status_user_id','retweeted_status_timestamp','expanded_urls'], axis=1)\n",
    "fltrd_rtng_dnm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fltrd_rtng_dnm.tweet_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assessing incorrect rating extraction\n",
    "fltrd_rtng_num=twt_arch_df[(twt_arch_df.rating_numerator!=10) & (twt_arch_df.rating_denominator==10) & twt_arch_df.in_reply_to_status_id.isnull() & twt_arch_df.retweeted_status_id.isnull()].drop(['in_reply_to_status_id','in_reply_to_user_id','retweeted_status_id','retweeted_status_user_id','retweeted_status_timestamp','expanded_urls'], axis=1)\n",
    "fltrd_rtng_num.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fltrd_rtng_num.tweet_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine top ratings\n",
    "fltrd_rtng_num.sort_values('rating_numerator', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify magnitude of tweets having float rating scale noted above\n",
    "twt_arch_df[twt_arch_df.text.str.contains('((?:\\d+\\.)\\d+)\\/(\\d+)')].drop(['in_reply_to_status_id','in_reply_to_user_id','retweeted_status_id','retweeted_status_user_id','retweeted_status_timestamp','expanded_urls'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for proper name extraction\n",
    "fltrd_name=twt_arch_df[twt_arch_df.name != 'None'].drop(['in_reply_to_status_id','in_reply_to_user_id','retweeted_status_id','retweeted_status_user_id','retweeted_status_timestamp','expanded_urls'], axis=1)\n",
    "fltrd_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect unusual names\n",
    "twt_arch_df.name.value_counts().to_frame().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess wrong extraction\n",
    "twt_arch_df[twt_arch_df.text.str.contains('name')].drop(['in_reply_to_status_id','in_reply_to_user_id','retweeted_status_id','retweeted_status_user_id','retweeted_status_timestamp','expanded_urls'], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess wrong extraction\n",
    "twt_arch_df[twt_arch_df.name.str.islower()].drop(['in_reply_to_status_id','in_reply_to_user_id','retweeted_status_id','retweeted_status_user_id','retweeted_status_timestamp','expanded_urls'], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess wrong stage extraction, substitute doggo in both conditions with other stages to switch display\n",
    "twt_arch_df[twt_arch_df.text.str.contains('doggo') & ~(twt_arch_df.doggo != 'None')].drop(['in_reply_to_status_id','in_reply_to_user_id','retweeted_status_id','retweeted_status_user_id','retweeted_status_timestamp','expanded_urls'], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess duplicate stages\n",
    "twt_arch_df[(twt_arch_df.doggo != 'None') & (twt_arch_df.floofer !='None')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess duplicate stages\n",
    "twt_arch_df[(twt_arch_df.doggo != 'None') & (twt_arch_df.pupper !='None')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess duplicate stages\n",
    "twt_arch_df[(twt_arch_df.doggo != 'None') & (twt_arch_df.puppo !='None')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess duplicate stages\n",
    "twt_arch_df[(twt_arch_df.doggo != 'None') & (twt_arch_df.pupper !='None') & (twt_arch_df.in_reply_to_status_id.isnull()) & (twt_arch_df.retweeted_status_id.isnull())].drop(['in_reply_to_status_id','in_reply_to_user_id','retweeted_status_id','retweeted_status_user_id','retweeted_status_timestamp','expanded_urls'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#assessmentoutcome\" style='color:#8D38C9'>Assessment outcome</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"imgdf\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_predicts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_predicts_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_predicts_df.describe().round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_predicts_df.jpg_url.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect duplicates\n",
    "img_predicts_df[img_predicts_df.jpg_url.duplicated()].sort_values('tweet_id').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess predictions credibility\n",
    "img_predicts_df[img_predicts_df.p1_conf>=0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assessing for false negative\n",
    "img_predicts_df[~(img_predicts_df.p1_dog) & ~(img_predicts_df.p2_dog) & ~(img_predicts_df.p3_dog)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assessing false positive\n",
    "img_predicts_df[(img_predicts_df.p1_dog) & (img_predicts_df.p2_dog) & (img_predicts_df.p3_dog)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess predictions credibility\n",
    "img_predicts_df[img_predicts_df.p1_conf==img_predicts_df.p1_conf.min()].append(img_predicts_df[img_predicts_df.p2_conf==img_predicts_df.p2_conf.min()]).append(img_predicts_df[img_predicts_df.p3_conf==img_predicts_df.p3_conf.min()]).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess predictions credibility\n",
    "img_predicts_df[img_predicts_df.p1_conf==img_predicts_df.p1_conf.max()].append(img_predicts_df[img_predicts_df.p2_conf==img_predicts_df.p2_conf.max()]).append(img_predicts_df[img_predicts_df.p3_conf==img_predicts_df.p3_conf.max()]).round(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#assessmentoutcome\" style='color:#8D38C9'>Assessment outcome</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"apidf\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_api_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_api_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#assessmentoutcome\" style='color:#8D38C9'>Assessment outcome</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"brdf\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_df.breed.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#assessmentoutcome\" style='color:#8D38C9'>Assessment outcome</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"brinfdf\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load df from saved csv to avoid running scrapping code\n",
    "breed_info_df=pd.read_csv('dog_breed_info_text.csv')\n",
    "breed_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_info_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_info_df.breed.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"assessmentoutcome\"></a>\n",
    "### Assessment outcome\n",
    "<a class=\"anchor\" id=\"qlt\"></a>\n",
    "* <a href=\"#qualityissues\" style='color:#8D38C9'>A-Quality Issues</a>\n",
    "    * <a href=\"#arcdf\" style='color:#C45AEC'>A.1-Twitter Archive Dataframe:</a>\n",
    "      * [A.1.1-Variables does not conform to our defined schema](#A1.1)\n",
    "      * [A.1.2-Time stamp dtype not properly identified](#A1.2)\n",
    "      * [A.1.3-Some tweets have misleading rating](#A1.3)\n",
    "      * [A.1.4-Dog name column has several wrong input ('a','the','this','an'), missing names are misrepresented and sometimes not properly extracted from tweet text](#A1.4)\n",
    "      * [A.1.5-Multiple dog stage occurrences for a single tweet](#A1.5)\n",
    "      * [A.1.6-Dog stage not properly extracted and missing values are misrepresented](#A1.6)\n",
    "    * <a href=\"#imgdf\" style='color:#C45AEC'>A.2-Image predictions Dataframe:</a>\n",
    "      * [A.2.1-Duplicated records, mainly related to retweets and replies](#A1.1)\n",
    "      * [A.2.2-Image prediction results are somewhat misleading](#A2.2)\n",
    "      * [A.2.3-Some breed names are incorrect and sometimes misleading](#A2.3)\n",
    "    * <a href=\"#brdf\" style='color:#C45AEC'>A.3-Breed Dataframe:</a>\n",
    "      * [A.3.1-Breed column's naming convention is not unified](#A2.3)\n",
    "    * <a href=\"#brinfdf\" style='color:#C45AEC'>A.4-Breed Info Dataframe:</a>\n",
    "      * [A.4.1-Breed column's naming convention is not unified](#A2.3)\n",
    "    ----\n",
    "<a class=\"anchor\" id=\"tid\"></a>\n",
    "* <a href=\"#tidinessissues\" style='color:#8D38C9'>B-Tidiness Issues</a>\n",
    "    * <a href=\"#arcdf\" style='color:#C45AEC'>B.1-Twitter Archive Dataframe:</a>\n",
    "      * [B.1.1-Tweet text column include both tweet text and links](#B1.1)\n",
    "      * [B.1.2-One variable in four columns. I.e: 'doggo', 'floofer' are different representations of a single variable 'Dog Stage'](#A1.6)\n",
    "      * [B.1.3-Total entries does not match that in Image predictions Dataframe](#B1.3)\n",
    "    * <a href=\"#imgdf\" style='color:#C45AEC'>B.2-Image predictions Dataframe:</a>\n",
    "      * [B.2.1-All breed information should be included in the Dataframe](#A2.3)\n",
    "\n",
    "\n",
    "**<a href=\"#masterdataframes\" style='color:#8D38C9'>Master Dataframe(s)</a>**\n",
    "\n",
    "**<a href=\"#analysis\" style='color:#8D38C9'>Analysis and visualization</a>**\n",
    "\n",
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cln\"></a>\n",
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making copies of gathered DataFrames\n",
    "df_twt_arch_c=twt_arch_df.copy()\n",
    "df_img_pred_c=img_predicts_df.copy()\n",
    "df_twt_api_c=twt_api_df.copy()\n",
    "df_breed_c=breed_df.copy()\n",
    "df_breed_inf_c=breed_info_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"qualityissues\"></a>\n",
    "### Quality Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"A1.1\"></a>\n",
    "#### A.1.1 - Variables does not conform to our defined schema\n",
    "---\n",
    "##### Define\n",
    "\n",
    "A total of 181(retweets) and 78(replies) are included in both archive and prediction Dataframe(s). We'd like to analyze original ratings of dogs only, so having retweets and replies in the dataframe does not follow our defined schema. We'll:\n",
    "\n",
    "- Identify non-null rows in all (in_reply_ / retweeted_) columns. this will also clear issue --> B.2.1 Duplicated records, mainly related to retweets and replies <--\n",
    "- Remove these columns all together since they wont be used in our analysis.\n",
    "- Bonus: Remove 'source' and 'expanded_urls' columns also since they won't be used in our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter and drop non-null rows, non null indicates that this tweet is either a reply or retweet\n",
    "df_twt_arch_c=df_twt_arch_c[df_twt_arch_c.in_reply_to_status_id.isnull() & df_twt_arch_c.in_reply_to_user_id.isnull() & df_twt_arch_c.retweeted_status_id.isnull() & df_twt_arch_c.retweeted_status_user_id.isnull() & df_twt_arch_c.retweeted_status_timestamp.isnull()]\n",
    "df_twt_arch_c.drop(['in_reply_to_status_id','in_reply_to_user_id','retweeted_status_id','retweeted_status_user_id','retweeted_status_timestamp','source','expanded_urls'], axis=1, inplace=True)\n",
    "df_twt_arch_c.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing retweets and replies data from predictions dataframe\n",
    "df_img_pred_c=df_img_pred_c[df_img_pred_c.tweet_id.isin(df_twt_arch_c.tweet_id)]\n",
    "df_img_pred_c.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_pred_c.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#qlt\" style='color:#8D38C9'>Quality Issues</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"A1.2\"></a>\n",
    "#### A.1.2 - Time stamp dtype not properly identified\n",
    "---\n",
    "##### Define\n",
    "- Change timestamp dtype to datetime\n",
    "- Bonus: change header format of 'timestamp' and 'name' columns to be more representative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dtype to date time and rename the header\n",
    "df_twt_arch_c['timestamp']=pd.to_datetime(df_twt_arch_c['timestamp']).dt.tz_localize(None)\n",
    "df_twt_arch_c.rename(columns={'timestamp': 'tweet_time_stamp', 'name': 'dog_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#qlt\" style='color:#8D38C9'>Quality Issues</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"A1.3\"></a>\n",
    "#### A.1.3 - Some tweets have misleading rating\n",
    "---\n",
    "##### Define\n",
    "\n",
    "here we have 3 issues as follows:\n",
    "- 17 tweets denominator is not matching the official rating scale of 10\n",
    "- 5 out of 17 have rating not properly extracted due to the existence of multiple ratings in the tweet text\n",
    "- 5 tweets have rating not properly extracted because the rating scale mentioned in tweet text is float not int\n",
    "\n",
    "We'll clean the above issues in a reverse order:\n",
    "- Apply correct rating if not properly extracted from tweet text\n",
    "- Change denominator of 17 to 10 to match official rating scale of 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter all tweets with wrong rating\n",
    "wrong_rating_df1 = df_twt_arch_c[(df_twt_arch_c.rating_denominator!=10) & df_twt_arch_c.text.str.contains('((?:\\d+\\.)?\\d+)\\/(\\d+)')]\n",
    "\n",
    "# extract correct rating to a separate dataframe\n",
    "correct_ratings_df = wrong_rating_df1.text.str.extractall('((?:\\d+\\.)?\\d+)\\/(\\d+)').unstack()\n",
    "\n",
    "# remove multiIndex and rename columns\n",
    "correct_ratings_df.columns = correct_ratings_df.columns.droplevel()\n",
    "correct_ratings_df.drop([0, 0], axis=1, inplace=True)\n",
    "correct_ratings_df.dropna(inplace=True)\n",
    "correct_ratings_df.columns=['rtng_num','rtng_dnm']\n",
    "\n",
    "# apply correct rating\n",
    "df_twt_arch_c.loc[df_twt_arch_c.index.isin(correct_ratings_df.index), 'rating_numerator'] = correct_ratings_df['rtng_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter all tweets with float rating\n",
    "wrong_rating_df2 = df_twt_arch_c[df_twt_arch_c.text.str.contains('((?:\\d+\\.)\\d+)\\/(\\d+)')]\n",
    "\n",
    "# extract correct rating to a separate dataframe\n",
    "float_ratings_df = wrong_rating_df2.text.str.extract('((?:\\d+\\.)?\\d+)\\/(\\d+)',expand=True)\n",
    "\n",
    "# rename columns\n",
    "float_ratings_df.columns=['rtng_num','rtng_dnm']\n",
    "\n",
    "# apply correct rating and dtype\n",
    "df_twt_arch_c.loc[df_twt_arch_c.index.isin(float_ratings_df.index), 'rating_numerator'] = float_ratings_df['rtng_num']\n",
    "df_twt_arch_c.rating_numerator=pd.to_numeric(df_twt_arch_c.rating_numerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.loc[(df_twt_arch_c.rating_denominator!=10) ,'rating_denominator']=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.loc[df_twt_arch_c.index.isin(correct_ratings_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.loc[df_twt_arch_c.index.isin(float_ratings_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c[df_twt_arch_c.rating_denominator!=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#qlt\" style='color:#8D38C9'>Quality Issues</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"A1.4\"></a>\n",
    "#### A.1.4 - Dog name column has several wrong input ('a','the','this','an'), missing names are misrepresented and sometimes not properly extracted from tweet text\n",
    "---\n",
    "##### Define\n",
    "Here we have 2 issues that we will address as follows:\n",
    "- Change lower case words and 'None' inputs to NaN. Lower case words are always not dog names.\n",
    "- Search and extract dog names that are already mentioned in tweet text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all lower case words and and missing names to 'not mentioned'\n",
    "df_twt_arch_c.loc[df_twt_arch_c.dog_name.str.islower(),'dog_name']= np.nan\n",
    "df_twt_arch_c.loc[df_twt_arch_c.dog_name=='None','dog_name']= np.nan\n",
    "\n",
    "# Search and extract all text following the word 'named'\n",
    "index_1=df_twt_arch_c.text.str.extract(r'(named?\\s\\w+.\\w+)').dropna()\n",
    "\n",
    "# slice out names,dog names mentioned in two forms either following 'is' or 'named'\n",
    "index_2=index_1[0].str.extract(r'(is?\\s\\w+)').dropna()\n",
    "index_3=index_1[0].str.extract(r'^(named\\s\\w+)').dropna()\n",
    "\n",
    "# apply correct names\n",
    "df_twt_arch_c.loc[df_twt_arch_c.index.isin(index_2.index), 'dog_name']=index_2[0].str.slice(3)\n",
    "df_twt_arch_c.loc[df_twt_arch_c.index.isin(index_3.index), 'dog_name']=index_3[0].str.slice(6)\n",
    "\n",
    "# this tweet had name mentioned after 'is', so will change individually\n",
    "df_twt_arch_c.loc[df_twt_arch_c.tweet_id==666739327293083650, 'dog_name']='Lugan'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.dog_name.value_counts().sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.loc[df_twt_arch_c.index.isin(index_2.index)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.loc[df_twt_arch_c.index.isin(index_3.index)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.loc[df_twt_arch_c.tweet_id==666739327293083650]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#qlt\" style='color:#8D38C9'>Quality Issues</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"A1.5\"></a>\n",
    "#### A.1.5 - Multiple dog stage occurrences for a single tweet\n",
    "---\n",
    "##### Define\n",
    "\n",
    "- Delete wrong entries based on tweet text.\n",
    "- Merge the multiple values into one for tweets having multiple dogs.\n",
    "- Bonus: Fix missing dog names if already included in tweet text but referenced as 'not mentioned'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter and apply correct dog stage\n",
    "df_twt_arch_c[(df_twt_arch_c.doggo != 'None') & (df_twt_arch_c.floofer !='None')].index\n",
    "df_twt_arch_c.loc[161,'doggo']='None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter and apply correct dog stage\n",
    "df_twt_arch_c[(df_twt_arch_c.doggo != 'None') & (df_twt_arch_c.pupper !='None')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes to be done based on visual inspection of above filter:\n",
    "# 358'doggo=None' - 446'doggo=None' - 416'Burke/Dexter pupper/doggo'  - 689'Lila/Maggie pupper/doggo' - 748'doggo' - 848'pupper/doggo' - 897'pupper/doggo'\n",
    "df_twt_arch_c.loc[[358,446,536,562],'doggo']='None'\n",
    "df_twt_arch_c.loc[[416,689],['dog_name','doggo','pupper']]=[('Burke/Dexter','pupper/doggo','None'),('Lila/Maggie','pupper/doggo','None')]\n",
    "df_twt_arch_c.loc[[748,536,562],'pupper']='None'\n",
    "df_twt_arch_c.loc[[848,897],['doggo','pupper']]='pupper/doggo','None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c[(df_twt_arch_c.doggo != 'None') & (df_twt_arch_c.puppo !='None')].index\n",
    "df_twt_arch_c.loc[154,'doggo']='None'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.iloc[[161,358,416,446,689,748,848,897,154]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#qlt\" style='color:#8D38C9'>Quality Issues</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"A1.6\"></a>\n",
    "#### A.1.6-Dog stage is not properly extracted, 'floof' in tweet text is ignored sometimes and missing values are misrepresented\n",
    "---\n",
    "##### Define\n",
    "Here we have 2 issues that we will address as follows:\n",
    "\n",
    "- Clear tidiness issue # *B.1.2 One variable in four columns I.e: 'doggo', 'floofer' are different representations of a single variable 'Dog Stage'*\n",
    "- Search in tweet text and replace dog stage if found in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'None' to properly join dog stage strings\n",
    "df_twt_arch_c[['doggo','floofer','pupper','puppo']] = df_twt_arch_c[['doggo', 'floofer','pupper','puppo']].replace('None', '')\n",
    "df_twt_arch_c['dog_stage'] =df_twt_arch_c[df_twt_arch_c.columns[6:]].apply(lambda x: ''.join(x),axis=1)\n",
    "df_twt_arch_c['dog_stage'].replace('',np.nan)\n",
    "# drop unwanted columns\n",
    "df_twt_arch_c.drop(['doggo','floofer','pupper','puppo'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search, extract and replace dog stage if found in tweet text\n",
    "df_twt_arch_c.loc[df_twt_arch_c.text.str.contains('doggo') & ~(df_twt_arch_c.dog_stage!='not mentioned'),'dog_stage']='doggo'\n",
    "df_twt_arch_c.loc[df_twt_arch_c.text.str.contains('floof') & ~(df_twt_arch_c.dog_stage!='not mentioned'),'dog_stage']='floofer'\n",
    "df_twt_arch_c.loc[df_twt_arch_c.text.str.contains('pupper') & ~(df_twt_arch_c.dog_stage!='not mentioned'),'dog_stage']='floofer'\n",
    "df_twt_arch_c.loc[df_twt_arch_c.text.str.contains('puppo') & ~(df_twt_arch_c.dog_stage!='not mentioned'),'dog_stage']='floofer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.dog_stage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.loc[df_twt_arch_c.text.str.contains('floof') & ~(df_twt_arch_c.dog_stage!='not mentioned')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.loc[df_twt_arch_c.text.str.contains('floof') & ~(df_twt_arch_c.dog_stage!='not mentioned')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.loc[df_twt_arch_c.text.str.contains('pupper') & ~(df_twt_arch_c.dog_stage!='not mentioned')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.loc[df_twt_arch_c.text.str.contains('puppo') & ~(df_twt_arch_c.dog_stage!='not mentioned')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#qlt\" style='color:#8D38C9'>Quality Issues</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"A2.2\"></a>\n",
    "#### A.2.2-Image prediction results are somewhat misleading\n",
    "---\n",
    "##### Define\n",
    "\n",
    "We'd like to analyze original ratings of __*dogs*__ only and since we can't fully place reliance on prediction results, due to the existence of several misleading entries; We'll use additional variable to guide our cleaning effort.\n",
    "\n",
    "- Add 'favorite count', 'retweet count' and 'rating numerator' to the dataframe. Most likely, higher engagement signals that this tweet is for an actual dog.\n",
    "- Reassess and drop tweets having no dog images\n",
    "- Drop any unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add engagement variables (favorite/retweet/rating) from twitter api and archive dataframes\n",
    "df_img_pred_c=pd.merge(df_img_pred_c,df_twt_api_c[['tweet_id','retweet_count','favorite_count']],on='tweet_id',how='left')\n",
    "df_img_pred_c=pd.merge(df_img_pred_c,df_twt_arch_c[['tweet_id','rating_numerator']],on='tweet_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_pred_c.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop tweets having no records in the api dataframe, these are most probably deleted tweets\n",
    "df_img_pred_c.dropna(axis=0,inplace=True)\n",
    "df_img_pred_c.reset_index(drop=True,inplace=True)\n",
    "# convert to proper dtype\n",
    "df_img_pred_c=df_img_pred_c.astype({'favorite_count':int,'retweet_count':int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter all false predictions\n",
    "df_false=df_img_pred_c[(df_img_pred_c.p1_dog ==False) & (df_img_pred_c.p2_dog==False) & (df_img_pred_c.p3_dog==False)]\n",
    "# display tweets with highest engagement values, drop unnecessary columns for more convenience\n",
    "df_false.sort_values('favorite_count', ascending=False).drop(['img_num','p1_dog','p2_dog','p3_dog'],axis=1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display tweets with highest rating, drop unnecessary columns for more convenience\n",
    "df_false.sort_values('rating_numerator', ascending=False).drop(['img_num','p1_dog','p2_dog','p3_dog'],axis=1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as per the accounts wiki, Nelson sees 30,000 likes on a post as being viral so we will consider this in filtering out false predictions\n",
    "# keep all false predictions above 30k favorite count and drop those with no dog images\n",
    "df_false_top_fav=df_false[(df_false.favorite_count > 30000) & ~(df_false.p1.str.contains('web_site|beaver|comic_book|revolver'))]\n",
    "# keep top false predictions with highest ratings\n",
    "df_false_top_rat=df_false[(df_false.rating_numerator > 200) & ~(df_false.p1.str.contains('microphone'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm cleaning\n",
    "df_false_top_fav.sort_values('favorite_count', ascending=False).drop(['img_num','p1_dog','p2_dog','p3_dog'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm cleaning\n",
    "df_false_top_rat.sort_values('favorite_count', ascending=False).drop(['img_num','p1_dog','p2_dog','p3_dog'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessment of true prediction credibility\n",
    "df_img_pred_c[(df_img_pred_c.p1_dog ==True) & (df_img_pred_c.p2_dog==True) & (df_img_pred_c.p3_dog==True)].sort_values('favorite_count', ascending=False).drop(['img_num','p1_dog','p2_dog','p3_dog'],axis=1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will rely on 1st prediction results as 70% are correct.\n",
    "# drop all false 1st predictions\n",
    "df_img_pred_c.drop(df_img_pred_c[(df_img_pred_c.p1_dog==False)].index,inplace=True)\n",
    "\n",
    "# add worng false predictions\n",
    "df_img_pred_c=df_img_pred_c.append([df_false_top_fav,df_false_top_rat],ignore_index=True)\n",
    "\n",
    "# rename for proper representation\n",
    "df_img_pred_c['breed']=df_img_pred_c['p1']\n",
    "\n",
    "# drop unwanted columns and reset index\n",
    "df_img_pred_c.drop(['img_num','p1','p1_conf','p1_dog','p2','p2_conf','p2_dog','p3','p3_conf','p3_dog'],axis=1,inplace=True)\n",
    "df_img_pred_c.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_pred_c.sort_values('rating_numerator', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_pred_c.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#qlt\" style='color:#8D38C9'>Quality Issues</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"A2.3\"></a>\n",
    "#### A.2.3-Some breed names are incorrect and sometimes misleading\n",
    "---\n",
    "##### Define\n",
    "- Unify Breed column's naming convention across the three dataframes this will also clear issue --> *A.3.1 and A.4.1- Breed column's naming convention is not unified* <--\n",
    "\n",
    "- Add breed info text to make a comprehensive breed dataframe, this will also clear issue --> *B.2.1 All breed information should be included in the Dataframe* <--\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcting wrong dog breed from both true and false prediction results\n",
    "\n",
    "# dict of correct breed, built based on visual inspection of tweet content\n",
    "correct_breed_dict={822872901745569793:'labrador retriever',\n",
    "                    739238157791694849:'siberian husky',\n",
    "                    879415818425184262:'basset hound',\n",
    "                    819004803107983360:'portuguese water dog',\n",
    "                    819006400881917954:'portuguese water dog',\n",
    "                    887517139158093824:'dachshund',\n",
    "                    849051919805034497:'labrador retriever',\n",
    "                    892420643555336193:'hokkaido',\n",
    "                    711694788429553666:'golden retriever',\n",
    "                    852311364735569921:'cavachon',\n",
    "                    870804317367881728:'portuguese water dog',\n",
    "                    762035686371364864:'belgian sheepdog',\n",
    "                    749981277374128128:'australian shepherd',\n",
    "                    731156023742988288:'Multiple'}\n",
    "\n",
    "# index list of tweets to be corrected\n",
    "index_list=df_img_pred_c[df_img_pred_c['tweet_id'].isin(correct_breed_dict.keys())].index\n",
    "\n",
    "# apply corerction, retrieve correct breed from breed dict that match tweet id found in index list\n",
    "for i in index_list:\n",
    "    df_img_pred_c.loc[[i],'breed']=correct_breed_dict[(df_img_pred_c.iloc[i]['tweet_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unify breed column str format\n",
    "df_img_pred_c.breed=df_img_pred_c.breed.str.lower().str.replace('_',' ').str.replace('-',' ')\n",
    "df_breed_c.breed=df_breed_c.breed.str.lower().str.replace('_',' ').str.replace('-',' ')\n",
    "df_breed_inf_c.breed=df_breed_inf_c.breed.str.replace('-',' ')\n",
    "\n",
    "# make a unifed breed dataframe\n",
    "df_img_pred_c=pd.merge(df_img_pred_c,df_breed_c[['breed','breed_info_link','breed_img_link']],on='breed',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify differences in breed name, nulls are breeds not found in the breed dataframe, I'll use breed name from there as a basis of unification\n",
    "df_img_pred_c[df_img_pred_c['breed_info_link'].isnull()].groupby(['breed']).groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the below line to query correct breed name from breed dataframe\n",
    "df_breed_c[df_breed_c.breed.str.contains('lhasa')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of breed names to be unified\n",
    "wrong_breed_keys_list=df_img_pred_c[df_img_pred_c['breed_info_link'].isnull()].groupby(['breed']).groups.keys()\n",
    "\n",
    "# list of correct breed name from breed datafram\n",
    "correct_breed_values_list=['airedale terrier','appenzeller sennenhunde','basset hound','cavalier king charles spaniel','bluetick coonhound',\n",
    "                                'boston terrier','brussels griffon','brittany','bullmastiff','cairn terrier','cardigan welsh corgi','chow chow','clumber spaniel',\n",
    "                                'dandie dinmont terrier','doberman pinscher','english springer spaniel','entlebucher mountain dog','american eskimo dog','german shepherd dog',\n",
    "                                'german shorthaired pointer','Multiple','belgian sheepdog','japanese chin','australian kelpie',\n",
    "                                'leonberger','lhasapoo','alaskan malamute','belgian malinois','maltese','xoloitzcuintli','poodle', 'Multiple', 'pekingese',\n",
    "                                'pembroke welsh corgi','redbone coonhound','scottish terrier','staffordshire bull terrier','poodle','poodle','toy fox terrier',\n",
    "                                'treeing walker coonhound','fox terrier']\n",
    "\n",
    "len(wrong_breed_keys_list)==len(correct_breed_values_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building correct breed dict from wrong keys and correct values, wrong keys will be used to index correct values\n",
    "correct_breed_name_dict=dict(list(zip(wrong_breed_keys_list,correct_breed_values_list)))\n",
    "\n",
    "# function to apply correct breed name on a dataframe column\n",
    "def correct_breed_name(df):\n",
    "    if df['breed'] in correct_breed_name_dict.keys():\n",
    "        correct_breed = correct_breed_name_dict[df['breed']]\n",
    "        return correct_breed\n",
    "    else:\n",
    "        return df['breed']\n",
    "\n",
    "# apply function on 'breed' column\n",
    "df_img_pred_c['breed'] = df_img_pred_c.apply(correct_breed_name, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update prediction's newly created breeds\n",
    "\n",
    "# unifying index of both dataframes for update, similar to 'vlookup'\n",
    "df_img_pred_c.index=df_img_pred_c.breed\n",
    "df_breed_c.index=df_breed_c.breed\n",
    "\n",
    "# updated new values\n",
    "df_img_pred_c.update(df_breed_c,overwrite=False)\n",
    "\n",
    "# reset index\n",
    "df_img_pred_c.reset_index(drop=True,inplace=True)\n",
    "df_breed_c.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# inspect\n",
    "df_img_pred_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_pred_c.loc[df_img_pred_c['breed_info_link'].isna()]\n",
    "\n",
    "# these images feature many dogs of mixed breeds, so will keep them referenced as 'Multiple'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add breed info text to the data frame for a quick glance instead of visiting the website\n",
    "df_img_pred_c=pd.merge(df_img_pred_c,df_breed_inf_c[['breed','breed_info_text']],on='breed',how='left')\n",
    "\n",
    "# inspect\n",
    "df_img_pred_c.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check nulls in new column, other are expected as we have two 'Multiple' breeds\n",
    "df_img_pred_c[df_img_pred_c.breed_info_text.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whats wrong with 'xoloitzuintli' ???\n",
    "df_breed_inf_c[df_breed_inf_c.breed.str.contains('xoloitzuintli')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated with correct name\n",
    "df_breed_inf_c.loc[382,'breed']='xoloitzcuintli'\n",
    "df_img_pred_c.index=df_img_pred_c.breed\n",
    "df_breed_inf_c.index=df_breed_inf_c.breed\n",
    "df_img_pred_c.update(df_breed_inf_c,overwrite=False)\n",
    "df_img_pred_c.reset_index(drop=True,inplace=True)\n",
    "df_breed_inf_c.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in index_list:\n",
    "    if any (df_img_pred_c.loc[[i],'breed']==correct_breed_dict[(df_img_pred_c.iloc[i]['tweet_id'])]):\n",
    "        print(i,'----All good, great job!')\n",
    "    else:\n",
    "        print('blep!', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_pred_c.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_pred_c.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_pred_c[df_img_pred_c['breed_info_link'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#qlt\" style='color:#8D38C9'>Quality Issues</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"tidinessissues\"></a>\n",
    "### Tidiness Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"B1.1\"></a>\n",
    "#### B.1.1-Tweet text column include both tweet text and link\n",
    "---\n",
    "##### Define\n",
    "\n",
    "- Split tweet text and link into separate columns\n",
    "- Bouns: change header'text' to 'tweet_text'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract, split and merge\n",
    "df_splitted_columns=df_twt_arch_c.text.str.split(r'(https?:(/{1,3})\\S+)',expand=True)\n",
    "df_twt_arch_c[['text','tweet_link']]=df_splitted_columns[[0,1]]\n",
    "df_twt_arch_c.rename(columns={'text':'tweet_text'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether to grab link for these tweets or not will be decided after cleaning next issue # B.1.3\n",
    "df_twt_arch_c[df_twt_arch_c.tweet_link.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#tid\" style='color:#8D38C9'>Tidiness Issues</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"B1.3\"></a>\n",
    "#### B.1.3-Total entries does not match that in Image prediction  Dataframe\n",
    "---\n",
    "##### Define\n",
    "Since our defined schema for this analysis is original ratings for dogs only, we'll:\n",
    "\n",
    "- Drop tweets from cleaned tweet archive that are not found in image prediction dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c=df_twt_arch_c[df_twt_arch_c.tweet_id.isin(df_img_pred_c.tweet_id)]\n",
    "df_twt_arch_c.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_pred_c.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_pred_c[~df_img_pred_c.tweet_id.isin(df_twt_arch_c.tweet_id)].sort_values('tweet_id',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets missing links are already droped\n",
    "df_twt_arch_c[df_twt_arch_c.tweet_link.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#tid\" style='color:#8D38C9'>Tidiness Issues</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"masterdataframes\"></a>\n",
    "### Master DataFrame(s)\n",
    "\n",
    "We'll create two main dataframes one for tweets another for breeds and will keep tweet id as well as favorite count in both. Considering that we'd like to analyze various drivers of higher engagement, it will be convenient if we have these figures in front of us in both dataframes.\n",
    "\n",
    "\n",
    "As we start analyzing data we will load main dataframes to sub ones (Doggo Tweets/Breeds), sorting and dropping columns that won't be used much in our analysis.\n",
    "\n",
    "\n",
    "* <a href=\"#maindf\" style='color:#8D38C9'>Main Dataframe(s)</a>\n",
    "\n",
    "* <a href=\"#doggotweet\" style='color:#8D38C9'>Sub-Doggo Tweets</a>\n",
    "\n",
    "* <a href=\"#doggobreed\" style='color:#8D38C9'>Sub-Doggo Breeds</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"maindf\"></a>\n",
    "### Main Dataframe(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "df_twt_arch_c=pd.merge(df_twt_arch_c,df_twt_api_c[['tweet_id','retweet_count','favorite_count']],on='tweet_id',how='left')\n",
    "# split observational units (tweet/breed) in separate dataframes\n",
    "df_img_pred_c=pd.merge(df_img_pred_c,df_twt_arch_c[['tweet_id','dog_name','dog_stage']],on='tweet_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "df_twt_arch_c.drop(columns=['dog_name','dog_stage'], inplace=True)\n",
    "df_img_pred_c.drop(columns=['retweet_count','rating_numerator'], inplace=True)\n",
    "\n",
    "# rename for better representation\n",
    "df_twt_arch_c.rename(columns={'rating_numerator':'dog_rating'},inplace=True)\n",
    "df_img_pred_c.rename(columns={'jpg_url':'dog_picture'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save master dataframe(s)\n",
    "df_twt_arch_c.to_csv('twitter_archive_master.csv',index=False)\n",
    "df_img_pred_c.to_csv('breed_master.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_pred_c.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twt_arch_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_pred_c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#assessmentoutcome\" style='color:#8D38C9'>Assessment outcome</a>**    \n",
    "**<a href=\"#analysis\" style='color:#8D38C9'>Analysis and visualization</a>**  \n",
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"doggotweet\"></a>\n",
    "### Doggo Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "df_twt_arch_c=pd.read_csv('twitter_archive_master.csv')\n",
    "# Make copies\n",
    "doggos_tweets_df=df_twt_arch_c.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doggos_tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doggos_tweets_df['tweet_time_stamp']=pd.to_datetime(doggos_tweets_df['tweet_time_stamp']).dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns to rearrange, tweets dataframe\n",
    "columns_tweets=doggos_tweets_df.columns.tolist()\n",
    "columns_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange columns\n",
    "columns_sort_tweets=columns_tweets[:3]+columns_tweets[5:6]+columns_tweets[6:8]+columns_tweets[3:4]\n",
    "doggos_tweets_df=doggos_tweets_df[columns_sort_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doggos_tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doggos_tweets_df.sort_values('favorite_count',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#assessmentoutcome\" style='color:#8D38C9'>Assessment outcome</a>**    \n",
    "**<a href=\"#analysis\" style='color:#8D38C9'>Analysis and visualization</a>**  \n",
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"doggobreed\"></a>\n",
    "### Doggo Breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_img_pred_c=pd.read_csv('breed_master.csv')\n",
    "# Make copy\n",
    "doggos_breeds_df=df_img_pred_c.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doggos_breeds_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns to rearrange, breeds dataframe\n",
    "columns_breeds=doggos_breeds_df.columns.tolist()\n",
    "columns_breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange columns, remove those that won't be used much in our analysis\n",
    "columns_sort_breeds=columns_breeds[:1]+columns_breeds[2:3]+columns_breeds[7:9]+columns_breeds[1:2]+columns_breeds[3:5]\n",
    "doggos_breeds_df=doggos_breeds_df[columns_sort_breeds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doggos_breeds_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doggos_breeds_df.sort_values('favorite_count',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#assessmentoutcome\" style='color:#8D38C9'>Assessment outcome</a>**      \n",
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"analysis\"></a>\n",
    "### Analysis and visualization\n",
    "\n",
    "* <a href=\"#time\" style='color:violet'>Account activity over time</a>\n",
    "\n",
    "* <a href=\"#tweet\" style='color:violet'>Key drivers of followers engagement</a>\n",
    "\n",
    "\n",
    "**<a href=\"#jmp2lnks\" style='color:#8D38C9'>Notebook Head</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"time\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Account activity over time\n",
    "\n",
    "- [WeRateDogs](https://en.wikipedia.org/wiki/WeRateDogs) account started in 2015 where peak creation of monthly tweets took place as 30% of tweets analyzed where created in the last two months of 2015. The scope of this analysis is the period starting Nov'15 till Aug'17 during which period new tweets creation was in continuous decline; However, followers' engagement in the form of favorits and retweets took a steady increase over the same period.\n",
    "\n",
    "- Decline in new tweet creation could be directly contributed to the filtration process, as noted in the account's wiki page, the account receive 800 to 1,000 submissions daily and work to narrow them down to about one high-quality piece of dog content per day. It's actually a sign of effective filtration process as few number of tweets generate higher engagement.\n",
    "\n",
    "- We can see the effect of this 'High-quality' content filteration strategy in the time series plot below. On May'16, June'16, August'16 single tweets caused spikes in user engagement trend and as of August a learning curve seems to have been established as user engagement took a steady increase till the end of the period. We'll explore later key drivers of followers engagement but we can conclude that content and context of the tweet plays a major role. Check these tweets, [1st](https://t.co/7wE9LTEXC4), [2nd](https://t.co/nTz3FtorBc), [3rd](https://t.co/DkBYaCAg2d), [5th](https://t.co/YcXgHfp1EC), [7th](https://t.co/AdPKrI8BZ1) ranks represent favorite count from highest to lowest, let's see if we both reached the same conclusion as you read on through the rest of this analysis.\n",
    "\n",
    "- It's clear that favorite as a type of engagment is taking precedence over retweet for this particular account, however, both have a positive correlation. It actually makes sense as favorite in general is a sign of appreciation and appeal which conforms to the context of these tweets.\n",
    "\n",
    "- Another interesting observation is that two independent yet identical tweets received different follower reactions. The [first](https://twitter.com/dog_rates/status/670668383499735048) posted on Nov'15 had a total favorite count of almost 10k, while the [second](https://twitter.com/dog_rates/status/892420643555336193) posted on Aug'17 had a total of 35K!. Setting aside that the tweet deserve higher engagement, I like donuts so this is a biased statement and also the doggo is cute, this highlights an effective practice of account management by seeking increased engagement through increasing tweet reach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating year and month for further analysis\n",
    "doggos_tweets_df['year'] = doggos_tweets_df['tweet_time_stamp'].dt.year\n",
    "doggos_tweets_df['month'] = doggos_tweets_df['tweet_time_stamp'].dt.month\n",
    "\n",
    "# # execluded aug'17 since we have only two records for this month\n",
    "time_interval_df=doggos_tweets_df[~((doggos_tweets_df.year == 2017) & (doggos_tweets_df.month == 8))]\n",
    "\n",
    "doggos_tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viral tweets timeframe\n",
    "time_interval_df.sort_values('favorite_count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of new tweets overtime\n",
    "time_interval_df.groupby(['year','month'])['tweet_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engagement trend overtime\n",
    "time_interval_df.groupby(['year','month'])['favorite_count'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup plot\n",
    "fig, ax = plt.subplots(1,1,figsize=(15,5), dpi=80)\n",
    "fig.suptitle('Account activity overtime', c='rosybrown', fontsize=15, ha= 'center')\n",
    "fig.subplots_adjust(top=0.8)\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "# Plot Line1 (Left Y Axis), resample timestamp by monthly bins\n",
    "time_interval_df.groupby(['tweet_time_stamp'])['tweet_id'].count().resample('1m').count().plot(ax=ax,c='red', label='New Tweet Count');\n",
    "\n",
    "# instantiate a second axes that shares the same x-axis\n",
    "ax2 = ax.twinx() \n",
    "\n",
    "# Plot Line2 (Right Y Axis), resample timestamp by monthly bins\n",
    "time_interval_df.groupby(['tweet_time_stamp'])['favorite_count'].mean().resample('1m').mean().plot(ax=ax2,c='purple', label='Average favorite Count');\n",
    "\n",
    "# instantiate a third axes that shares the same x-axis\n",
    "ax3 = ax.twinx()  \n",
    "\n",
    "# Plot Line3 (Right Y Axis), resample timestamp by monthly bins\n",
    "time_interval_df.groupby(['tweet_time_stamp'])['retweet_count'].mean().resample('1m').mean().plot(ax=ax3,c='orange', label='Average retweet Count');\n",
    "\n",
    "\n",
    "# Decoration\n",
    "ax.set_xlabel(\"Time interval\", c='chocolate', fontsize=15, x=.5)\n",
    "ax.set_ylabel(\"Tweet Count\", c='red', fontsize=15); ax2.set_ylabel(\"Average favorite and retweet Count\", c='purple', fontsize=15, x=.5)\n",
    "ax.grid(alpha=.3)\n",
    "ax3.axis('off')\n",
    "ax.spines[\"top\"].set_alpha(0.0); ax2.spines[\"top\"].set_alpha(0.0);ax3.spines[\"top\"].set_alpha(0.0)\n",
    "ax.spines[\"top\"].set_alpha(0.0); ax2.spines[\"top\"].set_alpha(0.0);ax3.spines[\"top\"].set_alpha(0.0)\n",
    "ax.legend(loc=4, bbox_to_anchor=(1, .10)); ax2.legend(loc=4, bbox_to_anchor=(1, .95)); ax3.legend(loc=4, bbox_to_anchor=(1, .30))\n",
    "ax3.set_yticks(np.linspace(ax2.get_yticks()[0], ax2.get_yticks()[-1], len(ax3.get_yticks())));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"tweet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key drivers of followers engagement  \n",
    "\n",
    "*  while dog name and stage may be included in each tweet this is not always the case, the following represent minimum content of each tweet:\n",
    "   - Media either picture or video\n",
    "   - Descriptive text\n",
    "   - Rating\n",
    "\n",
    "- We've incorporated image prediction results into our analysis;  these predictions are outputs of a neural network that can classify breeds of dogs based on their images. By comparing the relative featuring frequency of a specific breed to the corresponding engagement matrices which is in our case __*favorite count*__, we concluded that breed alone does not have a material impact on user engagement. For instance, [Golden retriever](https://dogtime.com/dog-breeds/golden-retriever) breed was featured 138 times but highest favorite count received for a single tweet was 76k while [Portuguese water dog](https://dogtime.com/dog-breeds/portuguese-water-dog) was featured only 3 times with highest favorite count of 85k; [French bulldog](https://dogtime.com/dog-breeds/french-bulldog), [Siberian husky](https://dogtime.com/dog-breeds/siberian-husky) and [Labrador retriever](https://dogtime.com/dog-breeds/labrador-retriever) were featured 25/21/94 times with highest favorite count of 112k/111k/150k respectively. It worth mentioning that image prediction results are not always correct but we did our best filtering out incorrect results specially for outliers and tweets having high user engagement.\n",
    "\n",
    "\n",
    "- Same as for dog rating, no material effect on user interactions because at the end of the day [They're good dogs Brent](https://www.vox.com/2018/7/23/17603566/dog-rates-good-dogs-brent-brant-got-a-puppy-meme) !. Average rating for tweets included in this data set is 13 where 75% of tweets have a rating of 12, only two outliers though and the top one have an interesting story behind it. [Atticus](https://thedailyatticus.wordpress.com/atticus/) was given highest rating of all time being 1776 , surprisingly the [tweet](https://t.co/GRXwMxLBkh) had relatively low user engagement of almost 5k favorite and 2k retweets. The tweet was created on 4th of July'16 as a celebration of US declaration of Independence day that took place on 1776.\n",
    "\n",
    "\n",
    "* What's driving higher user engagement? by exploring top favorite tweets and zooming in the outliers we can conclude that: \n",
    "  - [Videos](https://databox.com/videos-vs-images-in-facebook-ads) are the star of the show, 80% of top favorite tweets featured videos.\n",
    "  - Puppers and puppos (small dogs) shine, either alone or with another doggo. In fact, tweets featuring puppos received higher average rating than their counter parts.\n",
    "  - Doggos' biography counts!. Actually the reason behind why Portuguese water dog breed gained traction while being only featured three times is the fact that 2 of the three tweets featured ex US First doggo ['Sunny'](https://en.wikipedia.org/wiki/Sunny_(dog)) and his sister 'Bo'\n",
    "  - Pose matters. Check out these pictures from top favorite tweets [Pupper/Doggo](https://twitter.com/dog_rates/status/733109485275860992), [Puppo](https://twitter.com/dog_rates/status/889665388333682689), [Pupper](https://twitter.com/dog_rates/status/866450705531457537), [Zoey](https://twitter.com/dog_rates/status/870374049280663552), [Aja](https://t.co/lsPyyAiF1r). [Honey](https://twitter.com/dog_rates/status/1370171823829049344) is epic, it's a recent tweet though and not from the data set being analyzed.\n",
    "  - Timing makes a difference. 2nd top favorite tweet is for a [doggo](https://twitter.com/dog_rates/status/822872901745569793) participating in the 2017 [Women's March](https://en.wikipedia.org/wiki/2017_Women%27s_March)\n",
    "\n",
    "- So as we mentioned earlier, content and context influence user engagement. Tweets composed of a good mixture of both are most likely to receive higher user engagement, this also explains the reason why some tweets featuring same dog breed for example received widely varying favorite counts than others. If you are a dog owner seeking to celebritize your doggo then take this into consideration in your next photo session\n",
    "\n",
    "- [Golden retriever](https://dogtime.com/dog-breeds/golden-retriever) is the top featured breed in this dataset with a total featuring frequency of 138 times, it's one of the most popular dog breeds in the United States. The breeds friendly, tolerant attitude makes them great family pets, and their intelligence makes them highly capable working dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doggos_tweets_df.dog_rating.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top rated doggos\n",
    "doggos_tweets_df.sort_values('dog_rating',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viral tweets\n",
    "doggos_tweets_df.sort_values('favorite_count',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a dataframe for breed being the observational unit and favorite count/frequency as variables. focusing on favorite count being key engagement metrics\n",
    "\n",
    "df_1=doggos_breeds_df.groupby(['breed'],as_index=False)['favorite_count'].max().round().reset_index().rename(columns={'favorite_count':'max_fav_count'})\n",
    "df_2=doggos_breeds_df.groupby(['breed'],as_index=False)['favorite_count'].min().round().reset_index().rename(columns={'favorite_count':'min_fav_count'})\n",
    "df_3=doggos_breeds_df.groupby(['breed'],as_index=False)['favorite_count'].mean().round().reset_index().rename(columns={'favorite_count':'avg_fav_count'})\n",
    "df_4=doggos_breeds_df.groupby(['breed'],as_index=False)['favorite_count'].sum().round().reset_index().rename(columns={'favorite_count':'total_fav_count'})\n",
    "df_5=doggos_breeds_df.breed.value_counts().to_frame().reset_index().rename(columns={'index':'breed','breed':'featuring_frequency'})\n",
    "\n",
    "# list of df to merge\n",
    "data_frames_list=[df_1,df_2,df_3,df_4,df_5]\n",
    "\n",
    "# merge\n",
    "breed_stats_df = reduce(lambda  left,right: pd.merge(left,right,on=['breed'],how='outer'), data_frames_list)\n",
    "\n",
    "# drop extra columns\n",
    "breed_stats_df.drop(columns=['index_x','index_y'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_stats_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viral tweets stats in relation to breed category\n",
    "breed_stats_df.sort_values('max_fav_count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query data from tweets master data frame\n",
    "query_df=doggos_breeds_df[doggos_breeds_df.breed.str.contains('labrador retriever')]\n",
    "doggos_tweets_df[doggos_tweets_df.tweet_id.isin(query_df.tweet_id)].sort_values('favorite_count', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "\n",
    "# top 10 viral tweets categorized by breeds\n",
    "top_breeds_df = breed_stats_df[breed_stats_df.index.isin(breed_stats_df.sort_values('max_fav_count', ascending=False).head(10).index)]\n",
    "\n",
    "\n",
    "# setup plot\n",
    "fig, ax = plt.subplots(1,1,figsize=(15,5), dpi=80)\n",
    "fig.autofmt_xdate(rotation=45)\n",
    "\n",
    "# Number of bars, must match number of rows\n",
    "x = np.arange(10)\n",
    "# width \n",
    "w = 0.3\n",
    "\n",
    "# Plot Bars\n",
    "fav_count =ax.bar(x, top_breeds_df['max_fav_count'], width=w, color='sandybrown', align='center')\n",
    "\n",
    "#instantiate a 2nd axes that shares the same x-axis\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "feat_freq =ax2.bar(x + w, top_breeds_df['featuring_frequency'], width=w, color='rosybrown',align='center')\n",
    "\n",
    "# Decoration\n",
    "ax.set_ylabel(\"Maximum favorite count\", c='sandybrown', fontsize=15); ax2.set_ylabel(\"Featuring frequency\", c='rosybrown', fontsize=15)\n",
    "ax.spines[\"top\"].set_alpha(0.0); ax2.spines[\"top\"].set_alpha(0.0)\n",
    "plt.xticks(x + w /2, top_breeds_df.breed.str.capitalize())\n",
    "plt.title(\"Top 10 featured doggos breeds vs maximum favorite count\", c='chocolate', fontsize=15, ha= 'center', y=1.02)\n",
    "plt.legend([fav_count, feat_freq],['Maximum favorite count', 'Featuring frequency']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execulde missing names and stages\n",
    "doggo_name_df=doggos_breeds_df[~(doggos_breeds_df.dog_name.isnull())]\n",
    "doggo_stage_df=doggos_breeds_df[~(doggos_breeds_df.dog_stage.isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "\n",
    "# building a dataframe for stage being the observational unit and favorite count/frequency as variables.\n",
    "\n",
    "df_1 = doggo_stage_df.dog_stage.value_counts().to_frame().reset_index().rename(columns={'index':'dog_stage','dog_stage':'featuring_frequency'})\n",
    "df_2 = doggo_stage_df.groupby(['dog_stage'],as_index=False)['favorite_count'].max().round().reset_index().rename(columns={'favorite_count':'max_fav_count'})\n",
    "\n",
    "data_frames_list=[df_1,df_2]\n",
    "stage_stats_df = reduce(lambda  left,right: pd.merge(left,right,on=['dog_stage'],how='outer'), data_frames_list)\n",
    "stage_stats_df.drop(columns=['index'],axis=1,inplace=True)\n",
    "\n",
    "# Plot Bars\n",
    "fig, ax = plt.subplots(1,1,figsize=(15,5), dpi=80)\n",
    "\n",
    "# Number of bars, must match number of rows\n",
    "x = np.arange(5)\n",
    "# width\n",
    "w = 0.3\n",
    "\n",
    "fav_count =ax.bar(x, stage_stats_df['max_fav_count'], width=w, color='burlywood', align='center')\n",
    "\n",
    "#instantiate a 2nd axes that shares the same x-axis\n",
    "ax2 = ax.twinx()\n",
    "feat_freq =ax2.bar(x + w, stage_stats_df['featuring_frequency'], width=w,color='brown',align='center')\n",
    "\n",
    "\n",
    "# Decoration\n",
    "\n",
    "ax.set_ylabel(\"Maximum favorite count\", color='burlywood', fontsize=15); ax2.set_ylabel(\"Featuring frequency\", color='brown', fontsize=15)\n",
    "ax.spines[\"top\"].set_alpha(0.0); ax2.spines[\"top\"].set_alpha(0.0)\n",
    "plt.xticks(x + w /2, stage_stats_df.dog_stage.str.capitalize())\n",
    "plt.title(\"Top featured doggo stage vs maximum favorite count\", c='chocolate', fontsize=15, ha= 'center', y=1.02)\n",
    "plt.legend([fav_count, feat_freq],['Maximum favorite count', 'Featuring frequency']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "\n",
    "# breeds featured more than 10 times\n",
    "df = doggos_breeds_df.breed.value_counts().to_frame().reset_index().rename(columns={'index':'breed','breed':'featuring_frequency'})\n",
    "featuring_frequency_df = df[df.featuring_frequency > 10]\n",
    "\n",
    "# setup plot labels, box sizes and colors\n",
    "labels = featuring_frequency_df.apply(lambda x: str(x[0]) + \"\\n (\"+ str(x[1]) + \")\", axis=1)\n",
    "sizes = featuring_frequency_df['featuring_frequency'].values.tolist()\n",
    "colors = [plt.cm.Spectral(i/float(len(labels))) for i in range(len(labels))]\n",
    "\n",
    "# Draw Plot\n",
    "plt.figure(figsize=(30,14), dpi= 80)\n",
    "squarify.plot(sizes=sizes, label=labels, color=colors, alpha=1, bar_kwargs=dict(linewidth=2, edgecolor=\"#222222\"), text_kwargs=dict(fontsize=11));\n",
    "\n",
    "# Decorate\n",
    "plt.title('Doggo breeds featuring frequency', fontsize=20, y=1.01, c='brown')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "\n",
    "# featuring frequency\n",
    "df = doggo_name_df.dog_name.value_counts().to_frame().reset_index().rename(columns={'index':'dog_name','dog_name':'featuring_frequency'})\n",
    "\n",
    "# excluding single occurrence\n",
    "frequent_names_df=df[df.featuring_frequency>3].sort_values('dog_name')\n",
    "\n",
    "# number of rows for coloring each bars\n",
    "n = frequent_names_df['dog_name'].unique().__len__()+1\n",
    "\n",
    "# all colors are stored in the below list, use it to explore different ones\n",
    "all_colors = list(plt.cm.colors.cnames.keys())\n",
    "\n",
    "# setting up colors of each bar\n",
    "random.seed(len(frequent_names_df))\n",
    "c = random.choices(all_colors, k=n)\n",
    "\n",
    "# Plot Bars\n",
    "plt.figure(figsize=(16,10), dpi= 80)\n",
    "plt.bar(frequent_names_df['dog_name'], frequent_names_df['featuring_frequency'], color=c, width=.6)\n",
    "\n",
    "# displaying y axis numbers on top of the bars\n",
    "for i, val in enumerate(frequent_names_df['featuring_frequency'].values):\n",
    "    plt.text(i, val, float(val), horizontalalignment='center', verticalalignment='bottom', fontdict={'fontweight':500, 'size':12})\n",
    "\n",
    "# Decoration\n",
    "plt.gca().set_xticklabels(frequent_names_df['dog_name'], rotation=60, horizontalalignment= 'right')\n",
    "plt.title(\"Top featured doggo names\", fontsize=22, c='brown')\n",
    "plt.ylabel('featuring frequency')\n",
    "plt.ylim(0, 11)\n",
    "plt.gca().spines[\"top\"].set_alpha(0.0); plt.gca().spines[\"right\"].set_alpha(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Male doggos dominate, not fair !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#analysis\" style='color:#8D38C9'>Analysis and visualization</a>**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
